{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyecto Semestral - MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrantes:**\n",
    "\n",
    "- **Cristian Oyarzo M.**\n",
    "- **Sebastián Quenti A.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configuración e Importación de Librerías**\n",
    "\n",
    "En esta sección, se importarán las librerías necesarias para el desarrollo y análisis del proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc, make_scorer\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, auc, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proyecto se centra en el desarrollo de un modelo predictivo capaz de estimar la **probabilidad de morosidad** de los clientes de un banco. El objetivo principal es identificar aquellos clientes que son más propensos a incumplir en sus pagos, permitiendo a la institución financiera tomar decisiones informadas para gestionar riesgos y maximizar ingresos.\n",
    "\n",
    "El conjunto de datos incluye variables relacionadas con el perfil financiero y comportamental de los clientes. Estas variables abarcan tanto datos numéricos (por ejemplo, ingresos, montos adeudados) como categóricos (por ejemplo, historial crediticio). El problema presenta un marcado desbalance entre las clases, ya que la cantidad de clientes morosos es significativamente menor en comparación con los clientes no morosos.\n",
    "\n",
    "Dada la naturaleza desbalanceada de los datos, se seleccionó el **Área Bajo la Curva de Precisión-Recall (AUC-PR)** como métrica principal. Esta métrica es adecuada porque se centra en el rendimiento de la clase positiva (clientes morosos) y mide la capacidad del modelo para identificar correctamente a los clientes de alto riesgo mientras minimiza los falsos positivos. El uso de esta métrica es preferible frente a métricas como la precisión global (`accuracy`), que podría ser engañosa en un problema desbalanceado.\n",
    "\n",
    "Para resolver el problema, se utilizaron cuatro modelos supervisados:\n",
    "1. **XGBoost**: Un modelo basado en boosting que mostró ser el mejor entre los probados.\n",
    "2. **CatBoost**: Ideal para manejar datos categóricos de forma nativa.\n",
    "3. **LightGBM**: Un modelo eficiente y rápido para conjuntos de datos grandes.\n",
    "4. **Regresión Logística**: Utilizada como referencia base para el análisis comparativo.\n",
    "\n",
    "Antes del entrenamiento de los modelos, se realizaron transformaciones intermedias mediante **pipelines** y **ColumnTransformers**, que incluyeron:\n",
    "- Escalado de variables numéricas.\n",
    "- Codificación de variables categóricas.\n",
    "- Manejo de valores faltantes, cuando fue necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Etapa 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos proporcionados para esta etapa del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x0 = pd.read_parquet('X_t0.parquet')\n",
    "df_x1 = pd.read_parquet('X_t1.parquet')\n",
    "df_y0 = pd.read_parquet('y_t0.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se listan la totalidad de variables en la base de datos:\n",
    "1. **borrow_block_number**: Número de bloque en el que ocurrió el préstamo.\n",
    "2. **borrow_timestamp**: Marca temporal que indica el momento del préstamo.\n",
    "3. **wallet_address**: Dirección de la billetera asociada a las transacciones.\n",
    "4. **first_tx_timestamp**: Fecha y hora de la primera transacción registrada de la billetera.\n",
    "5. **last_tx_timestamp**: Fecha y hora de la última transacción registrada de la billetera.\n",
    "6. **wallet_age**: Tiempo de existencia de la billetera en días.\n",
    "7. **incoming_tx_count**: Cantidad total de transacciones entrantes a la billetera.\n",
    "8. **outgoing_tx_count**: Cantidad total de transacciones salientes desde la billetera.\n",
    "9. **net_incoming_tx_count**: Diferencia neta entre transacciones entrantes y salientes.\n",
    "10. **total_gas_paid_eth**: Suma total de gas pagado en Ethereum (ETH) por la billetera.\n",
    "11. **avg_gas_paid_per_tx_eth**: Promedio de gas pagado por transacción en ETH.\n",
    "12. **risky_tx_count**: Cantidad de transacciones clasificadas como riesgosas.\n",
    "13. **risky_unique_contract_count**: Número único de contratos asociados con transacciones riesgosas.\n",
    "14. **risky_first_tx_timestamp**: Marca temporal de la primera transacción riesgosa registrada.\n",
    "15. **risky_last_tx_timestamp**: Marca temporal de la última transacción riesgosa registrada.\n",
    "16. **risky_first_last_tx_timestamp_diff**: Diferencia de tiempo entre la primera y la última transacción riesgosa.\n",
    "17. **risky_sum_outgoing_amount_eth**: Suma total de ETH saliente en transacciones riesgosas.\n",
    "18. **outgoing_tx_sum_eth**: Suma total de ETH saliente en todas las transacciones.\n",
    "19. **incoming_tx_sum_eth**: Suma total de ETH entrante en todas las transacciones.\n",
    "20. **outgoing_tx_avg_eth**: Promedio de ETH saliente por transacción.\n",
    "21. **incoming_tx_avg_eth**: Promedio de ETH entrante por transacción.\n",
    "22. **max_eth_ever**: Máximo balance en ETH registrado en la billetera.\n",
    "23. **min_eth_ever**: Mínimo balance en ETH registrado en la billetera.\n",
    "24. **total_balance_eth**: Balance total actual de la billetera en ETH.\n",
    "25. **risk_factor**: Factor de riesgo calculado para la billetera.\n",
    "26. **total_collateral_eth**: Colateral total en ETH asociado a la billetera.\n",
    "27. **total_collateral_avg_eth**: Promedio de colateral total en ETH.\n",
    "28. **total_available_borrows_eth**: Cantidad total de ETH disponible para préstamos.\n",
    "29. **total_available_borrows_avg_eth**: Promedio de ETH disponible para préstamos.\n",
    "30. **avg_weighted_risk_factor**: Promedio ponderado del factor de riesgo.\n",
    "31. **risk_factor_above_threshold_daily_count**: Número de días en que el factor de riesgo estuvo por encima de un umbral.\n",
    "32. **avg_risk_factor**: Promedio general del factor de riesgo.\n",
    "33. **max_risk_factor**: Valor máximo del factor de riesgo registrado.\n",
    "34. **borrow_amount_sum_eth**: Suma total de los montos prestados en ETH.\n",
    "35. **borrow_amount_avg_eth**: Promedio de los montos prestados en ETH.\n",
    "36. **borrow_count**: Número total de transacciones de préstamo.\n",
    "37. **repay_amount_sum_eth**: Suma total de los montos reembolsados en ETH.\n",
    "38. **repay_amount_avg_eth**: Promedio de los montos reembolsados en ETH.\n",
    "39. **repay_count**: Número total de transacciones de reembolso.\n",
    "40. **borrow_repay_diff_eth**: Diferencia entre el monto prestado y el reembolsado en ETH.\n",
    "41. **deposit_count**: Número total de depósitos realizados.\n",
    "42. **deposit_amount_sum_eth**: Suma total de los depósitos en ETH.\n",
    "43. **time_since_first_deposit**: Tiempo transcurrido desde el primer depósito registrado.\n",
    "44. **withdraw_amount_sum_eth**: Suma total de los retiros en ETH.\n",
    "45. **withdraw_deposit_diff_if_positive_eth**: Diferencia positiva entre retiros y depósitos en ETH.\n",
    "46. **liquidation_count**: Número total de liquidaciones registradas.\n",
    "47. **time_since_last_liquidated**: Tiempo transcurrido desde la última liquidación.\n",
    "48. **liquidation_amount_sum_eth**: Suma total en ETH liquidada.\n",
    "49. **market_adx**: Índice direccional promedio del mercado.\n",
    "50. **market_adxr**: Índice direccional promedio suavizado del mercado.\n",
    "51. **market_apo**: Oscilador del precio promedio del mercado.\n",
    "52. **market_aroonosc**: Oscilador de Aroon para el mercado.\n",
    "53. **market_aroonup**: Valor de Aroon-Up del mercado.\n",
    "54. **market_atr**: Rango verdadero promedio del mercado.\n",
    "55. **market_cci**: Índice de canal de productos básicos del mercado.\n",
    "56. **market_cmo**: Oscilador de momento de Chande del mercado.\n",
    "57. **market_correl**: Correlación del mercado.\n",
    "58. **market_dx**: Índice direccional del mercado.\n",
    "59. **market_fastk**: Componente rápido K del estocástico del mercado.\n",
    "60. **market_fastd**: Componente rápido D del estocástico del mercado.\n",
    "61. **market_ht_trendmode**: Modo de tendencia Hilbert del mercado.\n",
    "62. **market_linearreg_slope**: Pendiente de la regresión lineal del mercado.\n",
    "63. **market_macd_macdext**: Componente MACD extendido del mercado.\n",
    "64. **market_macd_macdfix**: Componente MACD fijo del mercado.\n",
    "65. **market_macd**: Línea MACD del mercado.\n",
    "66. **market_macdsignal_macdext**: Señal MACD extendida del mercado.\n",
    "67. **market_macdsignal_macdfix**: Señal MACD fija del mercado.\n",
    "68. **market_macdsignal**: Línea de señal MACD del mercado.\n",
    "69. **market_max_drawdown_365d**: Máxima caída en 365 días del mercado.\n",
    "70. **market_natr**: Rango verdadero promedio normalizado del mercado.\n",
    "71. **market_plus_di**: Indicador direccional positivo del mercado.\n",
    "72. **market_plus_dm**: Movimiento direccional positivo del mercado.\n",
    "73. **market_ppo**: Oscilador de porcentaje de precio del mercado.\n",
    "74. **market_rocp**: Cambio porcentual del precio del mercado.\n",
    "75. **market_rocr**: Relación de cambio porcentual del mercado.\n",
    "76. **unique_borrow_protocol_count**: Número único de protocolos de préstamo utilizados.\n",
    "77. **unique_lending_protocol_count**: Número único de protocolos de préstamo activos.\n",
    "78. **target**: Variable objetivo que indica el estado de morosidad del cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el Análisis Exploratorio de Datos (EDA) se utilizó la herramienta de generación automática de perfiles con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143088c06ee641bd91bdb76899bd7c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m profile \u001b[38;5;241m=\u001b[39m ProfileReport(\n\u001b[0;32m      2\u001b[0m     df_x0,\n\u001b[0;32m      3\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnálisis Exploratorio de Datos Automático\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     explorative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Guarda el informe como un archivo HTML\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEDA_Reporte.html\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:374\u001b[0m, in \u001b[0;36mProfileReport.to_file\u001b[1;34m(self, output_file, silent)\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39massets_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(output_file\u001b[38;5;241m.\u001b[39mstem) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m     create_html_assets(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, output_file)\n\u001b[1;32m--> 374\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_file\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    377\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m output_file\u001b[38;5;241m.\u001b[39msuffix\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:491\u001b[0m, in \u001b[0;36mProfileReport.to_html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate and return complete template as lengthy string\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m        for using with frameworks.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:287\u001b[0m, in \u001b[0;36mProfileReport.html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhtml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_html\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:404\u001b[0m, in \u001b[0;36mProfileReport._render_html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTMLReport\n\u001b[1;32m--> 404\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[0;32m    407\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprogress_bar\n\u001b[0;32m    408\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m    409\u001b[0m         html \u001b[38;5;241m=\u001b[39m HTMLReport(copy\u001b[38;5;241m.\u001b[39mdeepcopy(report))\u001b[38;5;241m.\u001b[39mrender(\n\u001b[0;32m    410\u001b[0m             nav\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mnavbar_show,\n\u001b[0;32m    411\u001b[0m             offline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39muse_local_assets,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    419\u001b[0m             version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription_set\u001b[38;5;241m.\u001b[39mpackage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mydata_profiling_version\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    420\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:281\u001b[0m, in \u001b[0;36mProfileReport.report\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Root:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report \u001b[38;5;241m=\u001b[39m get_report_structure(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription_set\u001b[49m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\profile_report.py:263\u001b[0m, in \u001b[0;36mProfileReport.description_set\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescription_set\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseDescription:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set \u001b[38;5;241m=\u001b[39m \u001b[43mdescribe_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypeset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description_set\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\model\\describe.py:74\u001b[0m, in \u001b[0;36mdescribe\u001b[1;34m(config, df, summarizer, typeset, sample)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Variable-specific\u001b[39;00m\n\u001b[0;32m     73\u001b[0m pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 74\u001b[0m series_description \u001b[38;5;241m=\u001b[39m \u001b[43mget_series_descriptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypeset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet variable types\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\multimethod\\__init__.py:375\u001b[0m, in \u001b[0;36mmultimethod.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DispatchError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:99\u001b[0m, in \u001b[0;36mpandas_get_series_descriptions\u001b[1;34m(config, df, summarizer, typeset, pbar)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# TODO: use `Pool` for Linux-based systems\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mThreadPool(pool_size) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultiprocess_1d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDescribe variable:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseries_description\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(\n",
    "    df_x0,\n",
    "    title=\"Análisis Exploratorio de Datos Automático\",\n",
    "    explorative=True\n",
    ")\n",
    "\n",
    "# Guarda el informe como un archivo HTML\n",
    "profile.to_file(\"EDA_Reporte.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la altísima cantidad de variables en los datos, esta herramienta permite generar un informe detallado que incluye estadísticas descriptivas, detección de valores faltantes, correlaciones, distribuciones y otros aspectos clave de los datos, facilitando una comprensión global y eficiente de la información disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    22656\n",
       "0    21640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y0['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el análisis general de la base de datos se identificaron 73 variables numéricas y 3 variables categóricas, todas ellas sin valores nulos. Además, se descartó la variable '*wallet_address*', ya que su contenido corresponde a tipo id, lo cual no aporta valor para fines de predicción.\n",
    "\n",
    "Algunas de las variables siguen una distribución similar a normal como '*market_macd_macdext*', '*market_apo*'\n",
    "\n",
    "Realizando un `value_counts` a la columna target de **y_t0** se obtuvo que las clases se encuentran balanceadas, ya que son 22656 valores en 1 y 21640 valores en 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se fija una semilla aleatoria para garantizar la reproducibilidad de los resultados a lo largo del desarrollo del proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = 1323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocesamiento de Datos**\n",
    "\n",
    "En esta etapa, se preparan los datos para el modelado mediante la creación de **pipelines** y el uso de **ColumnTransformers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador personalizado para eliminar columnas específicas\n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "\n",
    "# Especificar las columnas categóricas y numéricas\n",
    "categorical_features = ['market_ht_trendmode', 'unique_borrow_protocol_count', 'unique_lending_protocol_count']\n",
    "numerical_features = [col for col in df_x0.columns if col not in categorical_features + ['wallet_address']]\n",
    "\n",
    "# Pipeline para las variables numéricas\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())  # Min-Max Scaler\n",
    "])\n",
    "\n",
    "# Aplicar ColumnTransformer para preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Aplicar transformación a numéricas\n",
    "        ('cat', 'passthrough', categorical_features)      # No hacer nada a las categóricas\n",
    "    ]\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")  # Forzar salida como DataFrame\n",
    "\n",
    "# Pipeline general con eliminación de la columna 'wallet_address'\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('drop_column', DropColumnTransformer(columns_to_drop=['wallet_address'])),  # Eliminar 'wallet_address'\n",
    "    ('preprocessor', preprocessor)          # Preprocesamiento por columnas\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de estos pipelines está diseñada para preparar los datos de forma eficiente y estructurada, optimizando su calidad y utilidad para modelos de machine learning. Se comienza eliminando la columna _'wallet_address'_, con un transformador personalizado, ya que contienen identificadores únicos que no aportan valor predictivo y podrían generar ruido en el análisis.\n",
    "\n",
    "Las variables numéricas se normalizan con `MinMaxScaler`, ajustándolas al rango [0, 1] para evitar desproporciones dimensionales y asegurar una contribución equilibrada en los modelos, especialmente en los basados en distancias. Por su parte, las variables categóricas no se transforman con `OneHotEncoder` o similares, ya que estas tres variables son binarias, por lo que es innecesario.\n",
    "\n",
    "Finalmente, se integraron todas estas etapas en un pipeline general, asegurando un flujo reproducible y consistente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide el conjunto de datos en tres partes para garantizar una evaluación adecuada del modelo:\n",
    "\n",
    "- **70%** para entrenamiento: Utilizado para ajustar el modelo.\n",
    "- **15%** para validación: Usado para evaluar los modelos generados por el proceso de búsqueda de hiperparámetros con `GridSearchCV`.\n",
    "- **15%** para prueba: Reservado para evaluar el rendimiento final del mejor modelo encontrado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento (70%), validación (15%) y prueba (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=rd, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=rd, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inicio de la Etapa de Modelado**\n",
    "\n",
    "Se comienza la construcción y evaluación de modelos predictivos con el objetivo de estimar la probabilidad de morosidad de los clientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métrica utilizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una métrica personalizada para AUC-PR\n",
    "def custom_auc_pr(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "# Crear un scorer basado en la métrica personalizada\n",
    "auc_pr_scorer = make_scorer(custom_auc_pr, response_method = 'predict_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modelo Base: Regresión Logística**\n",
    "\n",
    "Se implementa un modelo de Regresión Logística como referencia base para el análisis comparativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando búsqueda de hiperparámetros...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Mejores parámetros: {'C': 1, 'penalty': 'l1'}\n",
      "Mejor puntuación de validación cruzada (AUC-PR): 0.864619698206545\n",
      "AUC-PR en el conjunto de validación: 0.8578848730560438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crist\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir un modelo base\n",
    "log_reg = LogisticRegression(random_state=rd, solver='liblinear')\n",
    "\n",
    "# Definir un rango reducido de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Inverso de la regularización\n",
    "    'penalty': ['l1', 'l2']   # Tipo de regularización\n",
    "}\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rd)\n",
    "\n",
    "# Definir el GridSearchCV usando el conjunto de entrenamiento\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring=auc_pr_scorer, \n",
    "    cv=cv,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar el grid search con el conjunto de entrenamiento\n",
    "print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor puntaje de la validación cruzada\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación de validación cruzada (AUC-PR): {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluar el modelo con el conjunto de validación\n",
    "best_model_lr = grid_search.best_estimator_\n",
    "y_val_pred = best_model_lr.predict_proba(X_val)[:, 1]  # Obtener las probabilidades predichas para la clase positiva\n",
    "val_auc_pr = custom_auc_pr(y_val, y_val_pred)  # Calcular AUC-PR en el conjunto de validación\n",
    "print(f\"AUC-PR en el conjunto de validación: {val_auc_pr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modelo 1: XGBoost**\n",
    "\n",
    "Se utiliza el clasificador `XGBClassifier` de la librería `xgboost` para construir el primer modelo predictivo. Este modelo es conocido por su capacidad de manejar grandes volúmenes de datos y características con alta eficiencia, siendo una opción robusta para problemas de clasificación como el planteado en este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando búsqueda de hiperparámetros...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Mejores parámetros: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 1}\n",
      "Mejor puntuación de validación cruzada (AUC-PR): 0.9433971825531667\n",
      "AUC-PR en el conjunto de validación: 0.9435305574148607\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=rd, scale_pos_weight = 1)\n",
    "\n",
    "# Definir un rango reducido de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'reg_alpha': [0, 0.1, 1]  \n",
    "}\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rd)\n",
    "\n",
    "# Definir el GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=auc_pr_scorer, \n",
    "    cv=cv,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar el grid search\n",
    "print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor puntaje\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación de validación cruzada (AUC-PR): {grid_search.best_score_}\")\n",
    "# Evaluar el modelo con el conjunto de validación\n",
    "best_model_xgb = grid_search.best_estimator_\n",
    "y_val_pred = best_model_xgb.predict_proba(X_val)[:, 1]  # Obtener las probabilidades predichas para la clase positiva\n",
    "val_auc_pr = custom_auc_pr(y_val, y_val_pred)  # Calcular AUC-PR en el conjunto de validación\n",
    "print(f\"AUC-PR en el conjunto de validación: {val_auc_pr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modelo 2: CatBoost**\n",
    "\n",
    "Se utiliza el modelo de clasificación `CatBoostClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando búsqueda de hiperparámetros...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crist\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "4 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\crist\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\crist\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\crist\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\crist\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:26: Can't create train tmp dir: tmp\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\crist\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.87834046 0.90223055 0.87843496 0.90242479\n",
      " 0.88356773 0.91343651 0.88378173 0.9133142  0.88363982 0.91320047\n",
      " 0.88724362 0.91571331 0.88714714 0.91501164 0.88709128 0.91517074\n",
      " 0.89342577 0.93021208 0.89330031 0.92916474 0.89335708 0.92905603]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'depth': 5, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
      "Mejor puntuación de validación cruzada (AUC-PR): 0.9302120755133145\n",
      "AUC-PR en el conjunto de validación: 0.9281045158613274\n"
     ]
    }
   ],
   "source": [
    "# Definir un modelo base\n",
    "catboost = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    random_seed=rd\n",
    ")\n",
    "\n",
    "# Definir un rango reducido de hiperparámetros\n",
    "param_grid = {\n",
    "    'iterations': [100, 200],\n",
    "    'depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5] \n",
    "}\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rd)\n",
    "\n",
    "# Definir el GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=catboost,\n",
    "    param_grid=param_grid,\n",
    "    scoring=auc_pr_scorer, \n",
    "    cv=cv,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar el grid search\n",
    "print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor puntaje\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación de validación cruzada (AUC-PR): {grid_search.best_score_}\")    \n",
    "# Evaluar el modelo con el conjunto de validación\n",
    "best_model_cat = grid_search.best_estimator_\n",
    "y_val_pred = best_model_cat.predict_proba(X_val)[:, 1]  # Obtener las probabilidades predichas para la clase positiva\n",
    "val_auc_pr = custom_auc_pr(y_val, y_val_pred)  # Calcular AUC-PR en el conjunto de validación\n",
    "print(f\"AUC-PR en el conjunto de validación: {val_auc_pr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modelo 3: LightGBM**\n",
    "\n",
    "Se utiliza el modelo de clasificación `LGBMClassifier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando búsqueda de hiperparámetros...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[LightGBM] [Info] Number of positive: 15859, number of negative: 15148\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17127\n",
      "[LightGBM] [Info] Number of data points in the train set: 31007, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511465 -> initscore=0.045869\n",
      "[LightGBM] [Info] Start training from score 0.045869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mejores parámetros: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.1}\n",
      "Mejor puntuación de validación cruzada (AUC-PR): 0.9432474996299586\n",
      "AUC-PR en el conjunto de validación: 0.9428014639488884\n"
     ]
    }
   ],
   "source": [
    "# Definir un modelo base\n",
    "lightgbm = LGBMClassifier(random_state=rd)\n",
    "\n",
    "# Definir un rango reducido de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  \n",
    "    'max_depth': [3, 5],       \n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'reg_alpha': [0, 0.1]    \n",
    "}\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rd)\n",
    "\n",
    "# Definir el GridSearchCV usando el conjunto de entrenamiento\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lightgbm,\n",
    "    param_grid=param_grid,\n",
    "    scoring=auc_pr_scorer, \n",
    "    cv=cv,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "    \n",
    "# Ejecutar el grid search con el conjunto de entrenamiento\n",
    "print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor puntaje de la validación cruzada\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación de validación cruzada (AUC-PR): {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluar el modelo con el conjunto de validación\n",
    "best_model_l = grid_search.best_estimator_\n",
    "y_val_pred = best_model_l.predict_proba(X_val)[:, 1]  # Obtener las probabilidades predichas para la clase positiva\n",
    "val_auc_pr = custom_auc_pr(y_val, y_val_pred)  # Calcular AUC-PR en el conjunto de validación\n",
    "print(f\"AUC-PR en el conjunto de validación: {val_auc_pr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluación de Modelos en el Conjunto de Prueba**\n",
    "\n",
    "En esta sección, habiendo iterado las grillas en todos los modelos, se evalúan los cuatro modelos construidos previamente (XGBoost, CatBoost, LightGBM y Regresión Logística) en el conjunto de prueba para medir su rendimiento final. Para cada modelo, se calcula la métrica principal del proyecto, el **AUC-PR**, y se comparan los resultados para identificar el modelo con mejor desempeño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación en el conjunto de prueba:\n",
      "Logistic Regression - AUC-PR en el conjunto de prueba: 0.8645\n",
      "Reporte de Clasificación para Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      3246\n",
      "           1       0.78      0.72      0.74      3399\n",
      "\n",
      "    accuracy                           0.75      6645\n",
      "   macro avg       0.75      0.75      0.75      6645\n",
      "weighted avg       0.75      0.75      0.75      6645\n",
      "\n",
      "--------------------------------------------------\n",
      "XGBoost - AUC-PR en el conjunto de prueba: 0.9437\n",
      "Reporte de Clasificación para XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      3246\n",
      "           1       0.90      0.80      0.85      3399\n",
      "\n",
      "    accuracy                           0.85      6645\n",
      "   macro avg       0.86      0.85      0.85      6645\n",
      "weighted avg       0.86      0.85      0.85      6645\n",
      "\n",
      "--------------------------------------------------\n",
      "CatBoost - AUC-PR en el conjunto de prueba: 0.9302\n",
      "Reporte de Clasificación para CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      3246\n",
      "           1       0.88      0.77      0.82      3399\n",
      "\n",
      "    accuracy                           0.83      6645\n",
      "   macro avg       0.83      0.83      0.83      6645\n",
      "weighted avg       0.84      0.83      0.83      6645\n",
      "\n",
      "--------------------------------------------------\n",
      "LightGBM - AUC-PR en el conjunto de prueba: 0.9422\n",
      "Reporte de Clasificación para LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86      3246\n",
      "           1       0.90      0.80      0.85      3399\n",
      "\n",
      "    accuracy                           0.85      6645\n",
      "   macro avg       0.86      0.85      0.85      6645\n",
      "weighted avg       0.86      0.85      0.85      6645\n",
      "\n",
      "--------------------------------------------------\n",
      "Resultados finales:\n",
      "Logistic Regression: AUC-PR = 0.8645\n",
      "XGBoost: AUC-PR = 0.9437\n",
      "CatBoost: AUC-PR = 0.9302\n",
      "LightGBM: AUC-PR = 0.9422\n"
     ]
    }
   ],
   "source": [
    "# Evaluación en el conjunto de prueba\n",
    "def evaluate_model_on_test(model, model_name, X_test, y_test):\n",
    "    # Obtener probabilidades predichas para la clase positiva\n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcular AUC-PR\n",
    "    test_auc_pr = custom_auc_pr(y_test, y_test_pred)\n",
    "    print(f\"{model_name} - AUC-PR en el conjunto de prueba: {test_auc_pr:.4f}\")\n",
    "    \n",
    "    # Reporte de clasificación\n",
    "    y_test_pred_class = model.predict(X_test)\n",
    "    print(f\"Reporte de Clasificación para {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_test_pred_class))\n",
    "    print(\"-\" * 50)\n",
    "    return test_auc_pr\n",
    "\n",
    "# Evaluar los cuatro modelos\n",
    "print(\"Evaluación en el conjunto de prueba:\")\n",
    "results = {}\n",
    "\n",
    "# Evaluar Regresión Logística\n",
    "results['Logistic Regression'] = evaluate_model_on_test(best_model_lr, \"Logistic Regression\", X_test, y_test)\n",
    "\n",
    "# Evaluar XGBoost\n",
    "results['XGBoost'] = evaluate_model_on_test(best_model_xgb, \"XGBoost\", X_test, y_test)\n",
    "\n",
    "# Evaluar CatBoost\n",
    "results['CatBoost'] = evaluate_model_on_test(best_model_cat, \"CatBoost\", X_test, y_test)\n",
    "\n",
    "# Evaluar LightGBM\n",
    "results['LightGBM'] = evaluate_model_on_test(best_model_l, \"LightGBM\", X_test, y_test)\n",
    "\n",
    "\n",
    "# Comparación final de resultados\n",
    "print(\"Resultados finales:\")\n",
    "for model, auc_pr in results.items():\n",
    "    print(f\"{model}: AUC-PR = {auc_pr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entrega Parcial 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el modelo **XGBoost** obtuvo el mejor desempeño con un **AUC-PR de 0.9437**, se decide seleccionarlo como el modelo final para realizar una búsqueda más exhaustiva de hiperparámetros con una grilla ampliada. Esto permitirá explorar un espacio más amplio de configuraciones y, potencialmente, mejorar aún más su desempeño.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Para aprovechar al máximo el potencial del modelo **XGBoost**, se realiza una búsqueda ampliada de hiperparámetros utilizando **GridSearchCV**. En esta búsqueda:\n",
    "\n",
    "- Se utiliza la **totalidad de los datos de entrenamiento, validación y testeo combinados** para maximizar el uso de la información disponible y obtener una configuración más robusta.\n",
    "- La validación cruzada se realiza con **StratifiedKFold** (5 particiones), asegurando un equilibrio en las clases durante la evaluación.\n",
    "\n",
    "La nueva grilla de hiperparámetros incluye:\n",
    "\n",
    "- **`n_estimators`**: Número de árboles en el modelo, con valores entre 50 y 500.\n",
    "- **`max_depth`**: Profundidad máxima de los árboles, con valores de 3 a 10, para controlar la complejidad.\n",
    "- **`learning_rate`**: Tasa de aprendizaje, probando desde tasas bajas (0.001) hasta más agresivas (0.2).\n",
    "- **`reg_alpha` y `reg_lambda`**: Parámetros de regularización L1 y L2, explorando la influencia de la penalización en el ajuste.\n",
    "- **`subsample`**: Proporción de datos utilizados para construir cada árbol, con valores de 0.5 y 1.\n",
    "\n",
    "\n",
    "El uso de una grilla ampliada y de validación cruzada es crucial para garantizar que el modelo seleccionado no solo se ajuste bien a los datos disponibles, sino que también generalice de manera efectiva a nuevos datos. Este enfoque exhaustivo asegura que se exploren configuraciones más complejas, maximizando el desempeño del modelo en la tarea de predecir la probabilidad de morosidad.\n",
    "\n",
    "Cabe destacar que para la entrega parcial 1, en la etapa 1 en general, no se realizó el preprocesamiento de datos presente en el informe, debido a la carga académica de los integrantes del grupo y las características del modelo de resistencia a la escala de los datos y alta dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df_x0 = pd.read_parquet('X_t0.parquet')\n",
    "df_y0 = pd.read_parquet('y_t0.parquet')\n",
    "\n",
    "# Asegurarnos de que la variable objetivo sea un vector\n",
    "y = df_y0.values.ravel()\n",
    "\n",
    "# Eliminar la columna de texto\n",
    "text_column = 'wallet_address'\n",
    "X = df_x0.drop(columns=[text_column])\n",
    "\n",
    "# Definir una métrica personalizada para AUC-PR\n",
    "def custom_auc_pr(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "# Crear un scorer basado en la métrica personalizada\n",
    "auc_pr_scorer = make_scorer(custom_auc_pr, response_method = 'predict_proba')\n",
    "\n",
    "# Definir un modelo base\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=rd, scale_pos_weight = 1)\n",
    "\n",
    "# Definir una grilla ampliada de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 1, 10],\n",
    "    'reg_lambda': [1, 5, 10],\n",
    "    'subsample': [0.5, 1]\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rd)\n",
    "\n",
    "# Definir el GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=auc_pr_scorer, \n",
    "    cv=cv,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar el grid search\n",
    "print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor puntaje\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación de validación cruzada (AUC-PR): {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la búsqueda exhaustiva de hiperparámetros mediante `GridSearchCV`, los mejores parámetros encontrados para el modelo **XGBoost** fueron los siguientes:\n",
    "\n",
    "- **`learning_rate`:** 0.2  \n",
    "- **`max_depth`:** 10  \n",
    "- **`n_estimators`:** 500  \n",
    "- **`reg_alpha`:** 0  \n",
    "- **`reg_lambda`:** 1  \n",
    "- **`subsample`:** 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo de grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "X1 = df_x1.drop(columns=[text_column])\n",
    "\n",
    "def generateFiles(predict_data, clf_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    ---------------\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "\n",
    "    Ouput\n",
    "    ---------------\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict_proba(predict_data)[:, 1]\n",
    "    with open('./predictions.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    with ZipFile('predictions.zip', 'w') as zipObj:\n",
    "        zipObj.write('predictions.txt')\n",
    "    os.remove('predictions.txt')\n",
    "\n",
    "generateFiles(X1, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el mejor modelo\n",
    "joblib.dump(best_model, 'best_model1.pkl')\n",
    "\n",
    "print(\"El mejor modelo ha sido guardado en 'best_model1.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusión de la etapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo entregado en CodaLab entregó un **AUC-PR de 0.7914172453**, donde, si bien se obtuvo un buen resultado, no se hicieorn los procedimientos esperados para la entrega que podrían haber mejorado sustancialmente el modelo de predicción. Particularmente, utilizar el preprocesamiento, mejorar la capacidad de generalización del modelo y probar una mayor variedad de modelos e hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x0 = pd.read_parquet('X_t0.parquet')\n",
    "df_x1_v2 = pd.read_parquet('X_t1_v2.parquet')\n",
    "df_x2 = pd.read_parquet('X_t2.parquet')\n",
    "\n",
    "df_y0 = pd.read_parquet('y_t0.parquet')\n",
    "df_y1 = pd.read_parquet('y_t1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=1323, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=1323, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=1323, ...)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unir los datasets de X e Y\n",
    "df_x_combined = pd.concat([df_x0, df_x1_v2], ignore_index=True)\n",
    "df_y_combined = pd.concat([df_y0, df_y1], ignore_index=True)\n",
    "\n",
    "# Aplicar el pipeline al conjunto combinado\n",
    "X_preprocessed = full_pipeline.fit_transform(df_x_combined)\n",
    "\n",
    "# Configurar y entrenar el modelo XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    learning_rate=0.2,\n",
    "    max_depth=10,\n",
    "    n_estimators=500,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    subsample=1,\n",
    "    random_state=rd,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_preprocessed, df_y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFiles(predict_data, clf_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    ---------------\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "\n",
    "    Ouput\n",
    "    ---------------\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict_proba(predict_data)[:, 1]\n",
    "    with open('./predictions.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    with ZipFile('predictions.zip', 'w') as zipObj:\n",
    "        zipObj.write('predictions.txt')\n",
    "    os.remove('predictions.txt')\n",
    "    \n",
    "#  Preprocesar X2 y generar predicciones\n",
    "X2_preprocessed = full_pipeline.transform(df_x2)\n",
    "generateFiles(X2_preprocessed, xgb_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
